{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To always pass a fixed length vector as input, sentences are padded with dummy sequence to reach the maximum number of words allowed in the transformer. Each word in the sentence is then one hot encoded to get the vector representation. Each vector is then mapped to a 512 dimensional vector by passing through a feed forward network. Now, to this we will add a positional vector of same size. Finally the output is sent to attention block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the maximum number of words that can be allowed in the transformer\n",
    "max_sequence_length = 10\n",
    "\n",
    "# Dimesion of the word embedding\n",
    "d_model = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 4.])\n"
     ]
    }
   ],
   "source": [
    "even_i = torch.arange(0, d_model, 2).float()\n",
    "print(even_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.0000,  21.5443, 464.1590])\n"
     ]
    }
   ],
   "source": [
    "# Calculating the denominator part for even positions\n",
    "\n",
    "even_denominator = torch.pow(10000, even_i/d_model)\n",
    "print(even_denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 3., 5.])\n"
     ]
    }
   ],
   "source": [
    "odd_i = torch.arange(1, d_model, 2).float()\n",
    "print(odd_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.0000,  21.5443, 464.1590])\n"
     ]
    }
   ],
   "source": [
    "# Calculating the denominator part for odd positions\n",
    "\n",
    "odd_denominator = torch.pow(10000, (odd_i - 1)/d_model)\n",
    "print(even_denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n"
     ]
    }
   ],
   "source": [
    "# Calculating the numerator part\n",
    "\n",
    "position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sine and Cosine function are used in the positional encoding since they are periodic function and repeat after certain interval of time and constraints values between 1 and -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_positional_encoding = torch.sin(position / even_denominator)\n",
    "odd_positional_encoding = torch.cos(position / odd_denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.8415,  0.0464,  0.0022],\n",
      "        [ 0.9093,  0.0927,  0.0043],\n",
      "        [ 0.1411,  0.1388,  0.0065],\n",
      "        [-0.7568,  0.1846,  0.0086],\n",
      "        [-0.9589,  0.2300,  0.0108],\n",
      "        [-0.2794,  0.2749,  0.0129],\n",
      "        [ 0.6570,  0.3192,  0.0151],\n",
      "        [ 0.9894,  0.3629,  0.0172],\n",
      "        [ 0.4121,  0.4057,  0.0194]])\n"
     ]
    }
   ],
   "source": [
    "print(even_positional_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "print(even_positional_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000,  1.0000,  1.0000],\n",
      "        [ 0.5403,  0.9989,  1.0000],\n",
      "        [-0.4161,  0.9957,  1.0000],\n",
      "        [-0.9900,  0.9903,  1.0000],\n",
      "        [-0.6536,  0.9828,  1.0000],\n",
      "        [ 0.2837,  0.9732,  0.9999],\n",
      "        [ 0.9602,  0.9615,  0.9999],\n",
      "        [ 0.7539,  0.9477,  0.9999],\n",
      "        [-0.1455,  0.9318,  0.9999],\n",
      "        [-0.9111,  0.9140,  0.9998]])\n"
     ]
    }
   ],
   "source": [
    "print(odd_positional_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "print(odd_positional_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = torch.stack([even_positional_encoding, odd_positional_encoding], dim=2)\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
      "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
      "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
      "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
      "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
      "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
      "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
      "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
      "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
      "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])\n"
     ]
    }
   ],
   "source": [
    "positional_encoding = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "print(positional_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
