{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4EnrtWoW94E",
        "outputId": "f082f194-dd1c-4a3b-a78d-55195934bc52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HK5GQWeYXNLs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aR3S_T0lXaGu"
      },
      "outputs": [],
      "source": [
        "english_file = '/content/drive/MyDrive/data/english.txt'\n",
        "nepali_file = '/content/drive/MyDrive/data/nepali.txt'\n",
        "\n",
        "# To start a sentence\n",
        "START_TOKEN = ''\n",
        "\n",
        "# To end a sentence\n",
        "END_TOKEN = ''\n",
        "\n",
        "# To pad the sentences to make them all of equal length\n",
        "PADDING_TOKEN = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mJHozuNTZsy-"
      },
      "outputs": [],
      "source": [
        "english_vocabulary = [\n",
        "    START_TOKEN, ' ', '!', ':', ';', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "    ':', '<', '=', '>', '?', '@',\n",
        "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "    'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
        "    'Y', 'Z',\n",
        "    '[', '\\\\', ']', '^', '_', '`',\n",
        "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "    'y', 'z',\n",
        "    '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN\n",
        "]\n",
        "\n",
        "\n",
        "nepali_vocabulary = [\n",
        "    START_TOKEN, ' ', '!', ':', ';', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "    ':', '<', '=', '>', '?', 'ˌ',\n",
        "    'ँ', 'आ', 'इ', 'ा', 'ि', 'ी', 'ु', 'ू',\n",
        "    'क', 'ख', 'ग', 'घ', 'ङ',\n",
        "    'च', 'छ', 'ज', 'झ', 'ञ',\n",
        "    'ट', 'ठ', 'ड', 'ढ', 'ण',\n",
        "    'त', 'थ', 'द', 'ध', 'न',\n",
        "    'प', 'फ', 'ब', 'भ', 'म',\n",
        "    'य', 'र', 'ल', 'व', 'श', 'ष', 'स', 'ह',\n",
        "    '಼', 'ಽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॆ', 'े', 'ै', 'ो', 'ौ', '्', 'ॕ', 'ॖ', 'फ़', 'ॣ', 'ं', 'ः',\n",
        "    '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', PADDING_TOKEN, END_TOKEN\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vNgUIDQao-L",
        "outputId": "01a733be-ddfd-4771-80bf-f9b0ae75cf86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['प', 'ु', 'स', '्', 'त', 'क', 'ा', 'ल', 'य']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = 'पुस्तकालय'\n",
        "list(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WIjEjArsawLb"
      },
      "outputs": [],
      "source": [
        "# Creating a dictionary that maps words to numbers and vice versa\n",
        "index_to_nepali = {k:v for k,v in enumerate(nepali_vocabulary)}\n",
        "nepali_to_index = {v:k for k,v in enumerate(nepali_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c5a7X7dQbD_G"
      },
      "outputs": [],
      "source": [
        "with open(english_file, 'r') as file:\n",
        "    english_sentences = file.readlines()\n",
        "with open(nepali_file, 'r') as file:\n",
        "    nepali_sentences = file.readlines()\n",
        "\n",
        "# Limiting the number of sentences\n",
        "TOTAL_SENTENCES = 92000\n",
        "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
        "nepali_sentences = nepali_sentences[:TOTAL_SENTENCES]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DGemtIySbtJ1"
      },
      "outputs": [],
      "source": [
        "# Remove the \"/n\" after the end of every sentences\n",
        "english_sentences = [sentence.rstrip('\\n') for sentence in english_sentences]\n",
        "nepali_sentences = [sentence.rstrip('\\n') for sentence in nepali_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HWPduy0bdRb",
        "outputId": "66c27250-db27-4026-dc00-a2c6e7bed584"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['York is a collegiate university and every student is allocated to one of the university’s nine colleges. The ninth college was founded in 2014 and was named Constantine after the Roman emperor Constantine the Great, who was proclaimed Augustus in York in 306 AD.',\n",
              " '40:8 All my enemies were whispering against me . They were thinking up evils against me .',\n",
              " 'During the Presidency of Edmund J . James (1904-1920), James is credited for building the foundation of the large Chinese international student population on campus . James established ties with China through the Chinese Minister to the United States Wu Ting-Fang In addition, during James’s presidency, class rivalries and Bob Zuppke’s winning football teams contributed to campus morale . On June 11, 1929, the Alma Mater statue was unveiled . The Alma Mater was established by donations by the Alumni Fund and the classes of 1923-1929.',\n",
              " 'These sequences are intercepted by the ANSI.SYS driver which is loaded in CONFIG.SYS on a number of PC’s. The trojan redefines some keys on the',\n",
              " 'Do all my brothers, sisters, disillusioned, and hurting. I am sorry. I am a part of this as an American. But I am listening. I hear your pain.',\n",
              " \"+ See HSK's player statistics matches, target, Assist, short mM.\",\n",
              " 'A racing game attractive B [...]',\n",
              " 'Anonymous sources in newspapers of August 24 Annapurna Post report headlined “Deuba-Modi hold surprise meeting” datelined New Delhi has quoted unnamed source in one instance: Officials. Annapurna Post report headlined “Ministries in mess a... Read More',\n",
              " 'For wider volunteering opportunities in Newcastle contact the Volunteer Centre Newcastle, Broadacre House, Market Street, NE1 6HQ: Phone: 0191 3389696 Email: karen.watson@volunteermatters.org.uk Website: volunteercentrenewcastle.org.uk',\n",
              " 'IQ OPTION OFFICIAL LETTER TO AFFILIATES REGARDING THIS INFO:']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "english_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLgn5joVbjCe",
        "outputId": "e36ed8bf-7508-4021-c790-2d2191869683"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['न्यूयोर्क एक collegiate विश्वविद्यालय छ र हरेक विद्यार्थी विश्वविद्यालय गरेको नौ कलेज को एक विनियोजन गरिएको छ. नवौं कलेज मा स्थापित भएको थियो 2014 र रोमन सम्राट Constantine महान् पछि नाम थियो Constantine, जो मा योर्क अगस्तस घोषणा भएको थियो 306 ई. त्यहाँ निकट भविष्यमा दशौं कलेज निर्माण गर्ने योजना हो.',\n",
              " '40:8 मेरो सबै शत्रुलाई मेरो विरुद्धमा कानेखुसी थिए. तिनीहरू मेरो विरूद्धमा अप दुष्कर्मलाई सोच थियो.',\n",
              " 'पुस्तकालय, जसमा स्कूल संग खोलियो 1868, सुरु 1,039 मात्रा. पछि, PresidentEdmund जे. जेम्स, मा न्यासी को बोर्ड एक बोलीमा 1912, एक अनुसन्धान पुस्तकालय बनाउन प्रस्तावित. यसलाई अहिले संसारको सबैभन्दा ठूलो सार्वजनिक शैक्षिक संग्रह को छ. मा 1870, को Mumford घरको विद्यालयको प्रयोगात्मक खेत लागि एक मोडेल गोठ रूपमा निर्माण गरिएको थियो. को Mumford हाउस परिसर मा पुरानो संरचना रहन्छ. मूल विश्वविद्यालय हल (1871) को 4th भवन बनाइएको थियो; आज Illini संघ जहाँ खडा यसलाई उभिए.',\n",
              " 'यी दृश्यहरु पीसी गरेको एक नम्बर मा CONFIG.SYS मा लोड जो ANSI.SYS चालक अन्तर्खण्ड छन्। यो ट्रोजन अन केही कुञ्जीहरू redefines',\n",
              " 'मेरा सबै भाइहरूलाई के, बहिनीहरू, रनभुल्लमा, र चोट. म दु: खी छु. म एक अमेरिकी रूपमा यो अंश हुँ. तर म सुनिरहेको छु. म आफ्नो पीडा सुन्न.',\n",
              " '+ HSK गरेको खेलाडी तथ्याङ्क खेलहरू हेर्नुहोस्, लक्ष्य, सहयोग, kort m.m.',\n",
              " 'तपाईं एक खेल Enlai चाहनुहुन्छ भने [...]',\n",
              " 'कात्तिक ११ गते नागरिकमा प्रकाशित प्रकाश तिमल्सिनाले काठमाडौं डेटलाइनमा तयार पारेको समाचार “राष्ट्रपति आज चुनिँदै” मा नाम नखुलाइएको राष्ट्रपति कार्यालय स्रोतलाई उद्धृत गरिएको छ। नागरिकमा प्रकाशित पूर्ण बस्नेतले काठमा... विस्तारमा',\n",
              " 'न्यूक्यासल सम्पर्क स्वयंसेवी केन्द्र न्यूक्यासल मा व्यापक स्वयं सेवा मौका, Broadacre हाउस, बजार सडक, NE1 6HQ: फोन: 0191 3389696 इमेल: karen.watson@volunteermatters.org.uk वेबसाइट: volunteercentrenewcastle.org.uk',\n",
              " 'IQ OPTION यस जानकारी सन्दर्भमा सम्बद्ध गर्न औपचारिक पत्र:']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nepali_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xWsUZdJbb54",
        "outputId": "36bb8e6d-094e-46c8-b96f-73a33d7f3ca6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1023, 1024)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(len(x) for x in nepali_sentences), max(len(x) for x in english_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRKecKVhbb8t",
        "outputId": "4c4122d8-67d2-4d5c-aeea-77fcba9c600b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99th percentile length Nepali: 696.0\n",
            "99th percentile length English: 914.0\n"
          ]
        }
      ],
      "source": [
        "PERCENTILE = 99\n",
        "print( f\"{PERCENTILE}th percentile length Nepali: {np.percentile([len(x) for x in nepali_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtjvwnLDczr_",
        "outputId": "9b46e8be-1ffd-409f-96aa-63821b85a532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 92000\n",
            "Number of valid sentences: 6836\n"
          ]
        }
      ],
      "source": [
        "# Filter out data based on maximum sequence length and presence of token in vocab\n",
        "max_sequence_length = 200\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(nepali_sentences)):\n",
        "    nepali_sentence, english_sentence = nepali_sentences[index], english_sentences[index]\n",
        "    if is_valid_length(nepali_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(nepali_sentence, nepali_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(nepali_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qlE1hwDndiXp"
      },
      "outputs": [],
      "source": [
        "nepali_sentences = [nepali_sentences[i] for i in valid_sentence_indicies]\n",
        "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heotnHlnguhM",
        "outputId": "5066657a-e89f-438c-f6f8-c9d140c5da8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['मास्को मा स्पेस मौसम को तिहार.',\n",
              " 'कार्यालयहरू, काम गर्ने कोठाहरू, प्रतिनिधि कार्यालयहरू 300',\n",
              " 'विद्यालयको फोन नम्बरः ०२२२२४६५०९']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nepali_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-XZL89Rg2u_",
        "outputId": "b22ca8a3-c602-486f-e781-d48c3c1655c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Space weather Festival in Moscow.',\n",
              " 'Offices, working rooms, offices of representation 300',\n",
              " 'TEL: 022-224-6509 FAX: 022-224-6517 Establishment: July, 1992']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "english_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "emz6__atg4eg"
      },
      "outputs": [],
      "source": [
        "# Creating a Dataloader class\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, nepali_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.nepali_sentences = nepali_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.nepali_sentences[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VY4UJcKChC0C"
      },
      "outputs": [],
      "source": [
        "dataset = TextDataset(english_sentences, nepali_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOGGXjb4hHca",
        "outputId": "a225cdbf-0398-4456-cbbe-d038c6be8519"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6836"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlS8fw2rhJkL",
        "outputId": "a261aca7-0de3-46db-b0cb-a92dc5f3eaa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Offices, working rooms, offices of representation 300',\n",
              " 'कार्यालयहरू, काम गर्ने कोठाहरू, प्रतिनिधि कार्यालयहरू 300')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9Q9gGxtJhMIC"
      },
      "outputs": [],
      "source": [
        "batch_size = 3\n",
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyD_eF7JhW3W",
        "outputId": "aa93feab-2b48-49c0-827f-3df1fea249e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Space weather Festival in Moscow.', 'Offices, working rooms, offices of representation 300', 'TEL: 022-224-6509 FAX: 022-224-6517 Establishment: July, 1992'), ('मास्को मा स्पेस मौसम को तिहार.', 'कार्यालयहरू, काम गर्ने कोठाहरू, प्रतिनिधि कार्यालयहरू 300', 'विद्यालयको फोन नम्बरः ०२२२२४६५०९')]\n",
            "[('Department of Ancient and Medieval History', '27:6 The furnace tests the potter’s vessels, and the trial of the tribulation tests just men.', '27:6 The furnace tests the potter’s vessels, and the trial of the tribulation tests just men .'), ('प्राचीन र मध्यकालीन इतिहास विभाग', '27:6 आगोको भट्टी को पटर गरेको जहाजहरु परीक्षण, र कष्ट को परीक्षण बस मानिसहरू परीक्षण.', '27:6 आगोको भट्टी को पटर गरेको जहाजहरु परीक्षण, र कष्ट को परीक्षण बस मानिसहरू परीक्षण.')]\n",
            "[('in National', 'AMANKOUA, Cotonou I am a man, 49 years old, seeking a woman from 26 till 46', '5 March 2016 / 0 Comments / in 1989, PILOTS / by iron For Giampiero Fatemian the Paris-Dakar race ended prematurely for a bad ruzzolone that did keep many suspense.'), ('राष्ट्रिय', 'म हुं पुरुष, 49, खोज्दै महिला देखि 26 सम्म 46', '5 मार्च 2016 / 0 टिप्पणी / मा 1989, पाइलटहरूले / द्वारा फेरो')]\n",
            "[('The Narconon Program: Recognition &amp; Appreciation', 'Oil filling machine', 'Birds Free slot game'), ('नार्कोनन कार्यक्रम: पहिचान र मूल्यांकन', 'तेल भर्ने मेसिन', 'पक्षी नि: शुल्क स्लट खेल')]\n",
            "[('32:14 Then I will cause their waters to be very pure, and their rivers to be like oil, says the Lord God,', 'Photo Gallery Purnabiram The Profile of our Honors &amp; Awards', 'Double sheets lead curtain Double sheets lead screen'), ('32:14 त्यसपछि म आफ्नो पानी धेरै शुद्ध हुन गर्नाले, र आफ्नो नदीहरू तेल जस्तै हुन, प्रभु परमेश्वर भन्नुहुन्छ,', 'हाम्रा सम्मान र पुरस्कारको प्रोफाइल', 'डबल पानाहरू नेतृत्व स्क्रिन')]\n"
          ]
        }
      ],
      "source": [
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nT3bXCSUhqIG"
      },
      "outputs": [],
      "source": [
        "def tokenize(sentence, language_to_index, start_token=True, end_token=True):\n",
        "    sentence_word_indicies = [language_to_index[token] for token in list(sentence)]\n",
        "    if start_token:\n",
        "        sentence_word_indicies.insert(0, language_to_index[START_TOKEN])\n",
        "    if end_token:\n",
        "        sentence_word_indicies.append(language_to_index[END_TOKEN])\n",
        "    for _ in range(len(sentence_word_indicies), max_sequence_length):\n",
        "        sentence_word_indicies.append(language_to_index[PADDING_TOKEN])\n",
        "    return torch.tensor(sentence_word_indicies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfWqWG48iBLc",
        "outputId": "802256b7-584b-4db3-889d-5fae555f7c6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('32:14 Then I will cause their waters to be very pure, and their rivers to be like oil, says the Lord God,',\n",
              "  'Photo Gallery Purnabiram The Profile of our Honors &amp; Awards',\n",
              "  'Double sheets lead curtain Double sheets lead screen'),\n",
              " ('32:14 त्यसपछि म आफ्नो पानी धेरै शुद्ध हुन गर्नाले, र आफ्नो नदीहरू तेल जस्तै हुन, प्रभु परमेश्वर भन्नुहुन्छ,',\n",
              "  'हाम्रा सम्मान र पुरस्कारको प्रोफाइल',\n",
              "  'डबल पानाहरू नेतृत्व स्क्रिन')]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_FhokoWSiRin"
      },
      "outputs": [],
      "source": [
        "eng_tokenized, ne_tokenized = [], []\n",
        "for sentence_num in range(batch_size):\n",
        "    eng_sentence, ne_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
        "    eng_tokenized.append( tokenize(eng_sentence, english_to_index, start_token=False, end_token=False) )\n",
        "    ne_tokenized.append( tokenize(ne_sentence, nepali_to_index, start_token=True, end_token=True) )\n",
        "eng_tokenized = torch.stack(eng_tokenized)\n",
        "ne_tokenized = torch.stack(ne_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLPRzzEtiWa9",
        "outputId": "0b4174f3-80bd-4db0-d8ec-2880e0135b0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[22, 21, 29, 20, 23,  1, 54, 74, 71, 80,  1, 43,  1, 89, 75, 78, 78,  1,\n",
              "         69, 67, 87, 85, 71,  1, 86, 74, 71, 75, 84,  1, 89, 67, 86, 71, 84, 85,\n",
              "          1, 86, 81,  1, 68, 71,  1, 88, 71, 84, 91,  1, 82, 87, 84, 71, 15,  1,\n",
              "         67, 80, 70,  1, 86, 74, 71, 75, 84,  1, 84, 75, 88, 71, 84, 85,  1, 86,\n",
              "         81,  1, 68, 71,  1, 78, 75, 77, 71,  1, 81, 75, 78, 15,  1, 85, 67, 91,\n",
              "         85,  1, 86, 74, 71,  1, 46, 81, 84, 70,  1, 41, 81, 70, 15, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98],\n",
              "        [50, 74, 81, 86, 81,  1, 41, 67, 78, 78, 71, 84, 91,  1, 50, 87, 84, 80,\n",
              "         67, 68, 75, 84, 67, 79,  1, 54, 74, 71,  1, 50, 84, 81, 72, 75, 78, 71,\n",
              "          1, 81, 72,  1, 81, 87, 84,  1, 42, 81, 80, 81, 84, 85,  1,  9, 67, 79,\n",
              "         82,  4,  1, 35, 89, 67, 84, 70, 85, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98],\n",
              "        [38, 81, 87, 68, 78, 71,  1, 85, 74, 71, 71, 86, 85,  1, 78, 71, 67, 70,\n",
              "          1, 69, 87, 84, 86, 67, 75, 80,  1, 38, 81, 87, 68, 78, 71,  1, 85, 74,\n",
              "         71, 71, 86, 85,  1, 78, 71, 67, 70,  1, 85, 69, 84, 71, 71, 80, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98,\n",
              "         98, 98]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eng_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sjfUuFDj5KC",
        "outputId": "07c9a94b-d80a-45cd-9143-f0363fef506c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[108,  22,  21,  29,  20,  23,   1,  58,  90,  68,  74,  63,  49,  79,\n",
              "           1,  67,   1,  36,  64,  90,  62,  88,   1,  63,  78,  62,  80,   1,\n",
              "          61,  86,  69,  87,   1,  72,  81,  60,  90,  61,   1,  75,  81,  62,\n",
              "           1,  45,  69,  90,  62,  78,  70,  86,  15,   1,  69,   1,  36,  64,\n",
              "          90,  62,  88,   1,  62,  60,  80,  75,  69,  82,   1,  58,  86,  70,\n",
              "           1,  50,  74,  90,  58,  87,   1,  75,  81,  62,  15,   1,  63,  90,\n",
              "          69,  66,  81,   1,  63,  69,  67,  86,  72,  90,  71,  69,   1,  66,\n",
              "          62,  90,  62,  81,  75,  81,  62,  90,  49,  15, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108],\n",
              "        [108,  75,  78,  67,  90,  69,  78,   1,  74,  67,  90,  67,  78,  62,\n",
              "           1,  69,   1,  63,  81,  69,  74,  90,  43,  78,  69,  43,  88,   1,\n",
              "          63,  90,  69,  88,  64,  78,  37,  70, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108],\n",
              "        [108,  55,  65,  70,   1,  63,  78,  62,  78,  75,  69,  82,   1,  62,\n",
              "          86,  58,  83,  58,  90,  71,   1,  74,  90,  43,  90,  69,  79,  62,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108,\n",
              "         108, 108, 108, 108]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ne_tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tAZj3xCUlAUQ"
      },
      "outputs": [],
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "# There will be the usual mask in decoder that only looks at current and previous words\n",
        "\n",
        "# There will also be a padding mask in both encoder and decoder that will ignore the padding and everything associated with it\n",
        "\n",
        "def create_masks(eng_batch, ne_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, ne_sentence_length = len(eng_batch[idx]), len(ne_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      ne_chars_to_padding_mask = np.arange(ne_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, ne_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, ne_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, ne_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    print(f\"encoder_self_attention_mask {encoder_self_attention_mask.size()}: {encoder_self_attention_mask[0, :10, :10]}\")\n",
        "    print(f\"decoder_self_attention_mask {decoder_self_attention_mask.size()}: {decoder_self_attention_mask[0, :10, :10]}\")\n",
        "    print(f\"decoder_cross_attention_mask {decoder_cross_attention_mask.size()}: {decoder_cross_attention_mask[0, :10, :10]}\")\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu_BIcrmvjTR",
        "outputId": "ea2ac42e-0bd3-4545-c179-0c851479881e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "decoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
            "decoder_cross_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]),\n",
              " tensor([[[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]),\n",
              " tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "create_masks(batch[0], batch[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER1nUG67vnNS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
